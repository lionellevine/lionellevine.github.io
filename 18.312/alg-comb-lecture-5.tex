\documentclass[11pt]{article}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{latexsym}
\usepackage{epsfig}

\setlength{\evensidemargin}{.25in}
\setlength{\textwidth}{6in}
\setlength{\topmargin}{-0.4in}
\setlength{\textheight}{8.5in}


\newcommand{\handout}[5]{
   \renewcommand{\thepage}{#1-\arabic{page}}
   \noindent
   \begin{center}
   \framebox{
      \vbox{
    \hbox to 5.78in {{\sf 18.312: Algebraic Combinatorics} 
\hfill \sf #2 }
       \vspace{4mm}
       \hbox to 5.78in { {\Large \hfill #5  \hfill} }
       \vspace{2mm}
       \hbox to 5.78in { {\em #3 \hfill #4} }
      }
   }
   \end{center}
   \vspace*{4mm}
}

\newcommand{\lecture}[4]{\handout{#1}{#2}{Lecture date: #3}{Notes by: #4}{Lecture #1}}


\textwidth=6in
\oddsidemargin=0.25in
\evensidemargin=0.25in
\topmargin=-0.1in
\footskip=0.8in
\parindent=0.0cm
\parskip=0.3cm
\textheight=8.00in
\setcounter{tocdepth} {3}
\setcounter{secnumdepth} {2}
\sloppy

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{question}[theorem]{Question}
\newtheorem{answer}[theorem]{Answer}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{example}[theorem]{Example}
\newenvironment{proof}{\noindent \textbf{Proof:}}{$\Box$}

\newcommand{\N}{\mathbb N} % natural numbers 0,1,2,...
\newcommand{\Z}{\mathbb Z}  % integers
\newcommand{\R}{\mathbb R} % reals
\newcommand{\C}{\mathbb C} % complex numbers
\newcommand{\F}{\mathbb F} % finite fields

\newcommand{\floor}[1]{\left\lfloor {#1} \right\rfloor} % floor function
\newcommand{\ceiling}[1]{\left\lceil {#1} \right\rceil} % ceiling function
\newcommand{\binomial}[2]{\left( \begin{array}{c} {#1} \\ 
                        {#2} \end{array} \right)} % binomial coefficients
\newcommand{\modulo}[1]{\quad (\mbox{mod }{#1})} %congruences

\newcommand{\ignore}[1]{} % useful for commenting things out



\begin{document}
\lecture{5}{Lionel Levine}{Feb 15, 2011}{David Witmer} 
% replace n in the line above (and in the file name) by an actual integer
% replace Feb 1 by the date of the lecture 

\section{Stirling inverse matrices}

From last class, we have the following proposition:

\begin{proposition}
$$\sum_{k=0}^{n}{S(n,k)s(k,j)} = \delta_{nj}$$
where $S(n,k)$ are Stirling numbers of the second kind, $s(k,j)$ are signed Stirling numbers of the first kind such that
$$s(k,j) = (-1)^{k-j}c(k,j),$$
and 
$$
\delta_{nj} = 
     \begin{cases}
     1 & \textup{if } n = j \\
     0 & \textup{otherwise}  
     \end{cases}
$$
\end{proposition}

\begin{example}
Consider the $n = 4$ case, in which $S$ and $s$ are $4 \times 4$ matrices:

$$
S^{-1} =
{\begin{pmatrix}
1 & 0 & 0 & 0 \\
1 & 1 & 0 & 0 \\
1 & 3 & 1 & 0 \\
1 & 7 & 6 & 1
\end{pmatrix}}^{-1}
=~
\begin{pmatrix}
1 & 0 & 0 & 0 \\
-1 & 1 & 0 & 0 \\
2 & -3 & 1 & 0 \\
-6 & 11 & -6 & 1
\end{pmatrix}
= s
$$
\end{example}

\begin{proof}
Recall these two facts from last class:
\begin{fact}
$$\sum_{k=0}^n{c(n,k)x^k} = x(x+1)\cdots(x+n-1)$$
\end{fact}
\begin{fact}
$$\sum_{k=0}^n{S(n,k)x(x-1)\cdots(x-k+1)} = x^n$$
\end{fact}

First, we will find an expression analagous to fact 3 in terms of signed Stirling numbers of the first kind.

$$
\begin{aligned}
\sum_{k=0}^n{s(n,k)x^k} &= \sum_{k=0}^n{(-1)^{n-k}c(n,k)x^k} \\
                        &= (-1)^n \sum_{k=0}^n{c(n,k)(-x)^k} \\
                        &= (-1)^n (-x)(-x+1)\cdots(-x+n-1) ~~~~ \text{by fact 3} \\
                        &= x(x-1)\cdots(x-n+1) ~~~~ \text{since we have one -1 per factor}
\end{aligned}
$$

Now, let vector space $V_n = \{\text{polynomials in $x$ of degree $\leq n$ with constant term 0}\}$.  Consider two bases for $V_n$:
$$e_i = x^i$$
and
$$f_i = x(x-1)\cdots(x-i+1)$$
for $i$ from 1 to $n$.

Define $L:V_n \rightarrow V_n$ to be the linear operator such that $L(e_i) = f_i$.

From above, we know that
$$f_i = \sum_{k=0}^i{s(i,k)e_k}$$
so the matrix of $L$ in the basis $e_1,\ldots,e_n$ is $(s(i,k))_{i,k=1}^n$.

Then by fact 4, the matrix of $L^{-1}$ in the basis $f_1,\ldots,f_n$ is $(S(n,k))_{i,k=1}^n$.

That is,
$$\sum_{k=0}^n{S(n,k)f_k} = e_k.$$

Substituting in for $f_k$, we get
$$\sum_{k=0}^n{S(n,k)\sum_{j=0}^n{s(k,j)e_j}} = e_n.$$
Rearranging, we get
$$\sum_{j=0}^n{\left(\sum_{k=0}^n{S(n,k)s(k,j)}\right)e_j} = e_n.$$
Therefore,
$$\sum_{k=0}^n{S(n,k)s(k,j)} = \delta_{nj}.$$

\end{proof}


\section{Linear recurrences}
Recall the following example from last class:

\begin{example}
The Fibonacci sequence is defined by the recurrence
$$F_{n+2} = F_{n+1} + F_n$$ for $n \geq 1$ with $F_1 = 1$ and $F_2 = 1$.  We can write this recurrence in terms of the shift operator $E$ as
$$(E^2 - E - 1)F = 0.$$  Factoring, we see that
$$(E - \phi)(E - \bar{\phi}) = 0$$ where 
$$\phi = \frac{1 + \sqrt{5}}{2} = 1.618\ldots~~\text{and}~~\bar{\phi} = \frac{1 - \sqrt{5}}{2} = -0.618\ldots.$$
We can then write
$$F_n = a\phi^n + b\bar{\phi}^n.$$  Using the initial conditions $F_1 = F_2 = 1$, we find that $a = \frac{1}{\sqrt{5}}$ and $b = -\frac{1}{\sqrt{5}}$, so
$$F_n = \frac{1}{\sqrt{5}}(\phi^n - \bar{\phi}^n).$$
Since $\bar{\phi}^n$ rapidly becomes very small, we can say that
$$F_n \approx \frac{\phi^n}{\sqrt{5}}.$$
For instance, $F_{10} = 55$ and $\frac{\phi^{10}}{\sqrt{5}} = 55.0036\ldots$.
\end{example}

Now, we wish to generalize these results.  We wish to work over an algebraically closed field so we can factor.  We will use $\C$.

\begin{definition}
A sequence $s = (s_0, s_1, s_2, \ldots) \in \C^\infty$ obeys a linear recurrence of order $k$ if there exist $a_0, a_1, \ldots, a_{k-1} \in \C$ such that
$$s_{n+k} = \sum_{i=0}^{k-1}{a_i s_{n+i}}$$ for all $n \geq 0$.
\end{definition}

We can therefore write linear recurrences in the form
$$ p(E)s = 0$$ where $p$ is a polynomial in $\C[x]$ of degree $k$.

\begin{definition}
Suppose $p$ factors as
$$p(E) = (E - \phi_1)\ldots(E - \phi_k)$$ where $\phi_1, \ldots, \phi_k$ are distinct complex numbers.  Then $s$ satisfies a simple linear recurrence.
\end{definition}

\begin{theorem}
The sequence $s$ satisfies the simple linear recurrence $p(E)s = 0$ if and only if there exist $c_1, \ldots, c_k \in \C$ such that
$$s_n = c_1\phi_1^n + \ldots + c_k\phi_k^n.$$  That is, $s_n$ can be expressed as a linear combination of exponential sequences.
\end{theorem}

\begin{proof}
$p(E): \C^\infty \rightarrow  \C^\infty$ is a linear operator.  $\ker(p(E)) = \{s~|~p(E)s = 0\}$ is a subspace of $\C^\infty$.  Let $e_n^{(i)} = \phi_i^n$.  We want to show that $e^{(1)}, \ldots, e^{(k)}$ form a basis for $\ker(p(E))$.

First, we need to show that $e^{(i)} \in \ker(p(E))$.  The $e^{(i)}$'s are eigenvectors of the shift operator.
$$(Ee^{(i)})_n = e^{(i)}_{n+1} = \phi_i^{n+1} = \phi_i \phi_i^n = \phi_i e_n^{(i)},$$
Thus, $Ee^{(i)} = \phi_i e^{(i)}$, so $e^{(i)}$ is an eigenvector of $E$ with eigenvalue $\phi_i$.  This means that $e^{(i)} \in \ker(E - \phi_i)$, or $(E - \phi_i)e^{(i)} = 0$.  Since multiplication commutes, we can write $p(E) = q(E)(E - \phi_i)$ for some polynomial $q$. Then we have that
$$
\begin{aligned}
p(E)e^{(i)} &= q(E)(E - \phi_i)e^{(i)} \\
           &= q(E)0 \\
           &= 0,
\end{aligned}
$$
so $e^{(i)} \in \ker(p(E))$.

Next, we show that $e^{(1)}, \ldots, e^{(k)}$ are linearly independent.  Consider
$$\det{(e_j^{(i)})_{i=1,j=0}^{k,k-1}}
=
\det{
\begin{pmatrix}
1 & \cdots & 1 \\
\phi_1 & \cdots & \phi_k \\
\phi_1^2 & \cdots & \phi_k^2 \\
\vdots & \ddots & \vdots \\
\phi_1^{k-1} & \cdots & \phi_k^{k-1} 
\end{pmatrix}
}
$$
This is the Vandermonde determinant, so we see that
$$\det{(e_j^{(i)})_{i=1,j=0}^{k,k-1}} = \prod_{i < j}{(\phi_i - \phi_j)}.$$
Since we are dealing with a simple linear recurrence, all roots of $p$ must be distinct, so this determinant is nonzero.  This means that there is no linear dependence among the first $k$ terms of the sequences, so there is no linear dependence among the sequences.  Therefore, $e^{(1)},\cdots,e^{(k)}$ are linearly independent.

Finally, to show that $e^{(1)}, \ldots, e^{(k)}$ form a basis, we need to show that $\dim(\ker(p(E))) = k$.  A sequence $s \in \ker(p(E))$ is determined by its first $k$ terms $s_0,\ldots,s_{k-1}$ since all subsequent terms $s_k,s_{k+1},\ldots$ are determinted by the recurrence.  Let $f_j^{(i)} = \delta_{ij}$ for $1 \leq i,j \leq k$.  Then $f^{(1)},\ldots,f^{(k)}$ form a basis of size $k$.  All bases of $\ker(p(E))$ must have the same cardinality.  Therefore, $e^{(1)},\ldots,e^{(k)}$ form a basis for $\ker(p(E))$.
\end{proof}

\begin{example}
The sequence $s_n = 3^n - 2^n$ obeys a linear recurrence.  Let $\phi_1 = 3$ and $\phi_2 = 2$.  Then
$$p(E) = (E-3)(E-2) = E^2 - 5E + 6,$$
so our recurrence is
$$s_{n+2} - 5s_{n+1} + 6s_n = 0.$$
\end{example}

What if $p(E)$ has repeated roots?

\begin{example}
Consider the sequence $s$ such that
$$s_{n+3} = 3s_{n+2} - 3s_{n+1} + s_n.$$
Then
$$p(E) = E^3-3E^2+3E-1 = (E-1)^3 = D^3,$$ where $D = E-1$ is the difference operator.
One solution is $s_n = 1^n = 1$.  However, we expect to have two other linearly independent solutions since this a linear recurrence of order 3.  These two additional solutions are $s_n = n$ and $s_n = n^2$.

$D$ is analagous to the operator $\frac{d}{dt}$ for functions, so the corresponding differential equation to this recurrence is
$$\left[\frac{d}{dt}\right]^3 f(t) = 0.$$
Taking powers of the operator is the same as function composition, so this is equivalent to
$$\frac{d^3}{dt^3}f(t) = 0,$$
which has similar solutions $f(t) = 1$, $f(t) = t$, and $f(t) = t^2$.
\end{example}

This example brings us to the following lemma.

\begin{lemma}
$D^ms = 0$ if and only if $s_n = q(n)$ for some polynomial $q$ of degree less than or equal to $m-1$.
\end{lemma}

\begin{proof}
We want to show that $1,n,n^2,\ldots,n^{m-1}$ form a basis for $\ker(D_m)$.  We know that $\dim(\ker(D^m)) = m$ since a sequence that satisfies linear recurrence of order $m$ is determined by its first $m$ terms, which can be chosen arbitrarily as described above.

We first show that $1,n,n^2,\ldots,n^{m-1}$ are linearly independent.  If $1,n,n^2,\ldots,n^{m-1}$ were linearly dependent, then there would be $c_i$'s not all equal to zero such that
$$\sum_{i=0}^{m-1}{c_in^i} = 0~~\text{for all $n$}.$$
However, this would be a polynomial of finite degree with infinitely many roots.  Therefore, all of the $c_i$'s must be 0 and $1,n,n^2,\ldots,n^{m-1}$ must be linearly independent.

It remains to show that $1,n,n^2,\ldots,n^{m-1} \in \ker(D^m)$.  We will prove this by induction on $m$.  By our induction hypothesis, $1,n,n^2,\ldots,n^{m-2} \in \ker(D^{m-1})$, so
$$D^m[n^i] = D[D^{m-1}[n^i]] = D[0] = 0~~\text{for $i \leq m-2$}.$$
We now need to show that $D^m[n^{m-1}] = 0$.  We first find an expression for $D[n^{m-1}]$.
$$
\begin{aligned}
D[n^{m-1}] &= (E-1)n^{m-1} \\
          &= (n+1)^{m-1} - n^{m-1} \\
          &= \sum_{k=0}^{m-1}{\binomial{m-1}{k}n^k} - n^{m-1}~~~~\text{by the Binomial Theorem}\\
          &= \sum_{k=0}^{m-2}{\binomial{m-1}{k}n^k}~~~~\text{Note that this is a polynomial of degree $m-2$.}
\end{aligned}
$$
Then we substitute this expression into $D^m[n^{m-1}]$:
$$
\begin{aligned}
D^m[n^{m-1}] &= D^{m-1}[D[n^{m-1}]] \\
            &= D^{m-1}\left[\sum_{k=0}^{m-2}{\binomial{m-1}{k}n^k}\right] \\
            &= 0~~\text{by the inductive hypothesis since we are applying $D^{m-1}$ to a polynomial of degree $m-2$}
\end{aligned}
$$
Therefore, $1,n,n^2,\ldots,n^{m-1} \in \ker(D^m)$ and $1,n,n^2,\ldots,n^{m-1}$ form a basis for $\ker(D_m)$.
\end{proof}

So far, we have looked at two special cases of linear recurrences: distinct roots and powers of the difference operator.  We now consider the solution to a general linear recurrence.

\begin{theorem}
The sequence $s = (s_0,s_1,s_2,\dots)$ satisfies the linear recurrence
$$\prod_{i=1}^k{(E-\phi_i)^{m_i}}s = 0$$
if and only if
$$s_n = q_1(n)\phi_1^n + \ldots + q_k(n)\phi_k^n,$$
where each $q_i$ is a polynomial of degree at most $m_i-1$.
\end{theorem}
The proof is similar to the proofs of the previous lemma and theorem.  We will now continue to explore the connection between linear recurrences and differential equations.


\section{Exponential generating functions}

\begin{definition}
Given a sequence $s = (s_0,s_1,s_2,\dots)$, the exponential generating function of $s$ is the power series
$$\mathcal{F}_s(x) = s_0 + s_1x + \frac{s_2x^2}{2} + \ldots + \frac{s_nx^n}{n!} + \ldots.$$
\end{definition}

\begin{example}
Consider the sequence $s_n = 1$ for all $n$.  Then
$$\mathcal{F}_s(x) = \sum_{n=0}^{\infty}{\frac{x^n}{n!}} = e^x.$$
\end{example}

Why is there a factorial in the denominator of each term?

$$\frac{d}{dx}\left[\frac{x^n}{n!}\right] = \frac{nx^{n-1}}{n!} = \frac{x^{n-1}}{(n-1)!},$$
so
$$
\begin{aligned}
\frac{d}{dx}[\mathcal{F}_s(x)] &= \frac{d}{dx}\left[s_0 + s_1x + \frac{s_2x^2}{2} + \ldots + \frac{s^nx^n}{n!} + \ldots\right] \\
                               &= s_1 + s_2x + \ldots + \frac{s_nx^{n-1}}{(n-1)!} + \frac{s_{n+1}x^n}{n!} + \ldots \\
                               &= \mathcal{F}_{Es}(x).
\end{aligned}
$$
Differentiating an exponential generating function corresponds to shifting its sequence.  In particular, if $s$ obeys a linear recurrence $p(E)s = 0$, then its exponential generating function $\mathcal{F}_s(x)$ obeys the linear ordinary differential equation
$$p\left(\frac{d}{dx}\right)\mathcal{F}_s(x) = 0.$$
Why is this true?
$$p\left(\frac{d}{dx}\right)\mathcal{F}_s(x) = \mathcal{F}_{p(E)s}(x) = \mathcal{F}_0(x) = 0.$$

\begin{example}
Consider this ordinary differential equation:
$$f''(x) = f'(x) + f(x).$$
We can write $f(x)$ as
$$f(x) = \sum_{n=0}^{\infty}{\frac{s_nx^n}{n!}}$$
so finding $s$ satisfying the linear recurrence
$$s_{n+2} = s_{n+1} + s_n$$
results in $f(x)$ satisfying the ODE.  In this case, $s_n = F_n$, the Fibonacci Sequence, gives a solution.
\end{example}

\begin{example}
Consider the power series for $\sin{x}$.  We know that
$$\frac{d^2}{dx^2}\sin{x} = -\sin{x}.$$
In operator notation, we can write this as
$$\left[\left[\frac{d}{dx}\right]^2+1\right]\sin{x} = 0.$$
We can write $\sin{x}$ as
$$\sin{x} = \sum_{n=0}^{\infty}{\frac{s_nx^n}{n!}}$$
where $s$ satisfies the recurrence
$$s_{n+2} + s_n = 0$$
with $s_0 = 0$ and $s_1 = 1$ since $\sin{0} = 0$ and $\sin'{0} = \cos{0} = 1$.  The recurrence and initial values determine all of $s$, so we have that
$$\sin{x} = 0 + 1x + 0\frac{x^2}{2} + -1\frac{x^3}{3!} + \ldots.$$
\end{example}

Now, we will make a more explicit connection between the shift operator and the derivative.


\section{Relating $E$ and $\frac{d}{dx}$}

We can think of applying the shift operator to functions in the following manner:
$$
\begin{aligned}
(Ef)(x) &= f(x+1) \\
(E^2f)(x) &= f(x+2) \\
(E^hf)(x) &= f(x+h)~~\text{for $h \in \R$}.
\end{aligned}
$$

Then we can write
$$
\begin{aligned}
\frac{df}{dx} &= \lim_{h \rightarrow 0}{\frac{f(x+h)-f(x)}{h}} \\
              &= \lim_{h \rightarrow 0}{\frac{(E^hf)(x)-f(x)}{h}} \\
              &= \lim_{h \rightarrow 0}{\left(\frac{E^h-1}{h}\right)}f~~~~\text{Things become less rigorous here.} \\
\end{aligned}
$$
By L'Hopital's Rule,
$$
\begin{aligned}
\lim_{h \rightarrow 0}{\frac{a^h-1}{h}} &= \lim_{h \rightarrow 0}{\frac{a^h\ln{a}}{1}} \\
                                      &= \ln{a} 
\end{aligned}
$$
so, by analogy, we might say that
$$\lim_{h \rightarrow 0}{\left(\frac{E^h-1}{h}\right)}f = (\ln{E})f$$
so that
$$\frac{d}{dx} = \ln{E}.$$

There is a sense in which this is true, as we might then say based on knowledge of the Taylor series for $e^x$ that
$$E = e^{\frac{d}{dx}} = 1 + \frac{d}{dx} + \frac{1}{2}\left(\frac{d}{dx}\right)^2 + \ldots + \frac{1}{n!}\left(\frac{d}{dx}\right)^n + \ldots.$$
This leads to
$$Ef = f(x+1) = f(x) + f'(x) + \frac{1}{2}f''(x) + \ldots + \frac{1}{n!}f^{(n)}(x) + \ldots,$$
which is indeed the Taylor series for $f(x+1)$ centered at $f(x)$.

\end{document}
